{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: azure-ai-ml in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (1.9.0)\n",
                        "Requirement already satisfied: opencensus-ext-azure<2.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (1.1.9)\n",
                        "Requirement already satisfied: colorama<0.5.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (0.4.6)\n",
                        "Requirement already satisfied: azure-storage-file-datalake<13.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (12.12.0)\n",
                        "Requirement already satisfied: pydash<6.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (5.1.2)\n",
                        "Requirement already satisfied: typing-extensions<5.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (4.4.0)\n",
                        "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (6.0)\n",
                        "Requirement already satisfied: msrest>=0.6.18 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (0.7.1)\n",
                        "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (1.4.0)\n",
                        "Requirement already satisfied: tqdm<5.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (4.65.0)\n",
                        "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (2.4.0)\n",
                        "Requirement already satisfied: isodate in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (0.6.1)\n",
                        "Requirement already satisfied: strictyaml<2.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (1.7.3)\n",
                        "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (12.17.0)\n",
                        "Requirement already satisfied: azure-common<2.0.0,>=1.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (1.1.28)\n",
                        "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (1.29.1)\n",
                        "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (4.19.0)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (3.20.1)\n",
                        "Requirement already satisfied: azure-storage-file-share<13.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-ai-ml) (12.13.0)\n",
                        "Requirement already satisfied: six>=1.11.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.16.0)\n",
                        "Requirement already satisfied: requests>=2.18.4 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (2.28.1)\n",
                        "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (38.0.4)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.30.2)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.9.2)\n",
                        "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (23.1.0)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (2023.7.1)\n",
                        "Requirement already satisfied: packaging>=17.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (22.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml) (2023.7.22)\n",
                        "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\n",
                        "Requirement already satisfied: opencensus<1.0.0,>=0.11.2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.2)\n",
                        "Requirement already satisfied: psutil>=5.6.3 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.5)\n",
                        "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (1.14.0)\n",
                        "Requirement already satisfied: python-dateutil>=2.6.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\n",
                        "Requirement already satisfied: msal<2.0.0,>=1.20.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.23.0)\n",
                        "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.0.0)\n",
                        "Requirement already satisfied: cffi>=1.12 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (1.15.1)\n",
                        "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.11.1)\n",
                        "Requirement already satisfied: opencensus-context>=0.1.3 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.4)\n",
                        "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (2.0.4)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.26.14)\n",
                        "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.1)\n",
                        "Requirement already satisfied: pycparser in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (2.21)\n",
                        "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.22.0)\n",
                        "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.60.0)\n",
                        "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.20.3)\n",
                        "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.7.0)\n",
                        "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\n",
                        "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.0)\n",
                        "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.3.1)\n",
                        "Requirement already satisfied: pywin32>=226 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (305.1)\n",
                        "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.5.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Requirement already satisfied: azure-identity in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (1.14.0)\n",
                        "Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-identity) (1.29.1)\n",
                        "Requirement already satisfied: cryptography>=2.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-identity) (38.0.4)\n",
                        "Requirement already satisfied: msal<2.0.0,>=1.20.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-identity) (1.23.0)\n",
                        "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-identity) (1.0.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (4.4.0)\n",
                        "Requirement already satisfied: requests>=2.18.4 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (2.28.1)\n",
                        "Requirement already satisfied: six>=1.11.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (1.16.0)\n",
                        "Requirement already satisfied: cffi>=1.12 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\n",
                        "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msal<2.0.0,>=1.20.0->azure-identity) (2.4.0)\n",
                        "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.7.0)\n",
                        "Requirement already satisfied: pycparser in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
                        "Requirement already satisfied: pywin32>=226 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity) (305.1)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (3.4)\n",
                        "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (2.0.4)\n",
                        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (1.26.14)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (2023.7.22)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n",
                        "Requirement already satisfied: azureml-sdk in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (1.52.0)\n",
                        "Requirement already satisfied: azureml-train-core~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-train-automl-client~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-dataset-runtime[fuse]~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-core~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-pipeline~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: ndg-httpsclient<=0.5.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (0.5.1)\n",
                        "Requirement already satisfied: SecretStorage<4.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (3.3.3)\n",
                        "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (38.0.4)\n",
                        "Requirement already satisfied: azure-mgmt-authorization<4,>=0.40.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (3.0.0)\n",
                        "Requirement already satisfied: adal<=1.2.7,>=1.2.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.2.7)\n",
                        "Requirement already satisfied: packaging<=23.0,>=20.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (22.0)\n",
                        "Requirement already satisfied: azure-mgmt-keyvault<11.0.0,>=0.40.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (10.2.3)\n",
                        "Requirement already satisfied: azure-mgmt-containerregistry<11,>=8.2.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (10.1.0)\n",
                        "Requirement already satisfied: pytz in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (2022.7)\n",
                        "Requirement already satisfied: azure-core<2.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.29.1)\n",
                        "Requirement already satisfied: jmespath<2.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.0.1)\n",
                        "Requirement already satisfied: azure-mgmt-resource<=22.0.0,>=15.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (22.0.0)\n",
                        "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (2.8.2)\n",
                        "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (3.3.1)\n",
                        "Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.1.28)\n",
                        "Requirement already satisfied: argcomplete<3 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (2.1.2)\n",
                        "Requirement already satisfied: azure-mgmt-storage<=21.0.0,>=16.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (21.0.0)\n",
                        "Requirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (2.28.1)\n",
                        "Requirement already satisfied: docker<7.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (6.1.3)\n",
                        "Requirement already satisfied: backports.tempfile in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.0)\n",
                        "Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (0.6.4)\n",
                        "Requirement already satisfied: humanfriendly<11.0,>=4.7 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (10.0)\n",
                        "Requirement already satisfied: contextlib2<22.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (21.6.0)\n",
                        "Requirement already satisfied: knack~=0.10.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (0.10.1)\n",
                        "Requirement already satisfied: jsonpickle<4.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (3.0.2)\n",
                        "Requirement already satisfied: pathspec<1.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (0.11.2)\n",
                        "Requirement already satisfied: PyJWT<3.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (2.4.0)\n",
                        "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (0.61.1)\n",
                        "Requirement already satisfied: msrest<=0.7.1,>=0.5.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (0.7.1)\n",
                        "Requirement already satisfied: pyopenssl<24.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (22.0.0)\n",
                        "Requirement already satisfied: msal<2.0.0,>=1.15.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.23.0)\n",
                        "Requirement already satisfied: urllib3<2.0.0,>=1.23 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.26.14)\n",
                        "Requirement already satisfied: msal-extensions<=1.0.0,>=0.3.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.0.0)\n",
                        "Requirement already satisfied: pkginfo in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-core~=1.52.0->azureml-sdk) (1.9.6)\n",
                        "Requirement already satisfied: numpy!=1.19.4,<1.24 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (1.23.5)\n",
                        "Requirement already satisfied: pyarrow<=11.0.0,>=0.17.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (8.0.0)\n",
                        "Requirement already satisfied: azureml-dataprep<4.12.0a,>=4.11.3a in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (4.11.7)\n",
                        "Requirement already satisfied: fusepy<4.0.0,>=3.0.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (3.0.1)\n",
                        "Requirement already satisfied: azureml-pipeline-core~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-pipeline~=1.52.0->azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-pipeline-steps~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-pipeline~=1.52.0->azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-telemetry~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-train-automl-client~=1.52.0->azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: azureml-automl-core~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-train-automl-client~=1.52.0->azureml-sdk) (1.52.0.post1)\n",
                        "Requirement already satisfied: azureml-train-restclients-hyperdrive~=1.52.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-train-core~=1.52.0->azureml-sdk) (1.52.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0->azureml-core~=1.52.0->azureml-sdk) (4.4.0)\n",
                        "Requirement already satisfied: six>=1.11.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-core<2.0.0->azureml-core~=1.52.0->azureml-sdk) (1.16.0)\n",
                        "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-mgmt-authorization<4,>=0.40.0->azureml-core~=1.52.0->azureml-sdk) (1.4.0)\n",
                        "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azure-mgmt-keyvault<11.0.0,>=0.40.0->azureml-core~=1.52.0->azureml-sdk) (0.6.1)\n",
                        "Requirement already satisfied: azure-identity>=1.7.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (1.14.0)\n",
                        "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (6.0)\n",
                        "Requirement already satisfied: jsonschema in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (4.19.0)\n",
                        "Requirement already satisfied: azureml-dataprep-native<39.0.0,>=38.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (38.0.0)\n",
                        "Requirement already satisfied: dotnetcore2<4.0.0,>=3.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (3.1.23)\n",
                        "Requirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (2.0.0)\n",
                        "Requirement already satisfied: azureml-dataprep-rslex~=2.18.5dev0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (2.18.7)\n",
                        "Requirement already satisfied: applicationinsights in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from azureml-telemetry~=1.52.0->azureml-train-automl-client~=1.52.0->azureml-sdk) (0.11.10)\n",
                        "Requirement already satisfied: cffi>=1.12 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.52.0->azureml-sdk) (1.15.1)\n",
                        "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from docker<7.0.0->azureml-core~=1.52.0->azureml-sdk) (0.58.0)\n",
                        "Requirement already satisfied: pywin32>=304 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from docker<7.0.0->azureml-core~=1.52.0->azureml-sdk) (305.1)\n",
                        "Requirement already satisfied: pyreadline3 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from humanfriendly<11.0,>=4.7->azureml-core~=1.52.0->azureml-sdk) (3.4.1)\n",
                        "Requirement already satisfied: tabulate in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from knack~=0.10.0->azureml-core~=1.52.0->azureml-sdk) (0.8.10)\n",
                        "Requirement already satisfied: pygments in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from knack~=0.10.0->azureml-core~=1.52.0->azureml-sdk) (2.16.1)\n",
                        "Requirement already satisfied: portalocker<3,>=1.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msal-extensions<=1.0.0,>=0.3.0->azureml-core~=1.52.0->azureml-sdk) (2.7.0)\n",
                        "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.52.0->azureml-sdk) (1.3.1)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.52.0->azureml-sdk) (2023.7.22)\n",
                        "Requirement already satisfied: pyasn1>=0.1.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.52.0->azureml-sdk) (0.5.0)\n",
                        "Requirement already satisfied: bcrypt>=3.2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.52.0->azureml-sdk) (4.0.1)\n",
                        "Requirement already satisfied: pynacl>=1.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.52.0->azureml-sdk) (1.5.0)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.52.0->azureml-sdk) (3.4)\n",
                        "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.52.0->azureml-sdk) (2.0.4)\n",
                        "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.52.0->azureml-sdk) (1.7.1)\n",
                        "Requirement already satisfied: jeepney>=0.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from SecretStorage<4.0.0->azureml-core~=1.52.0->azureml-sdk) (0.8.0)\n",
                        "Requirement already satisfied: backports.weakref in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from backports.tempfile->azureml-core~=1.52.0->azureml-sdk) (1.0.post1)\n",
                        "Requirement already satisfied: pycparser in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.52.0->azureml-sdk) (2.21)\n",
                        "Requirement already satisfied: distro>=1.2.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from dotnetcore2<4.0.0,>=3.0.0->azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (1.8.0)\n",
                        "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.52.0->azureml-sdk) (3.2.1)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema->azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (2023.7.1)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema->azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (0.30.2)\n",
                        "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema->azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (23.1.0)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\mustafaj\\appdata\\local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages (from jsonschema->azureml-dataprep<4.12.0a,>=4.11.3a->azureml-dataset-runtime[fuse]~=1.52.0->azureml-sdk) (0.9.2)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "#%pip install azure-ai-formrecognizer==3.2.0\n",
                "%pip install azure-ai-ml\n",
                "%pip install azure-identity\n",
                "%pip install azureml-sdk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "import-mlclient"
            },
            "outputs": [],
            "source": [
                "# Handle to the workspace\n",
                "from azure.ai.ml import MLClient\n",
                "\n",
                "# Authentication package\n",
                "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
                "\n",
                "try:\n",
                "    credential = DefaultAzureCredential()\n",
                "    # Check if given credential can get token successfully.\n",
                "    credential.get_token(\"https://management.azure.com/.default\")\n",
                "except Exception as ex:\n",
                "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
                "    credential = InteractiveBrowserCredential()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create a handle to workspace"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "ml_client"
            },
            "outputs": [],
            "source": [
                "# Get a handle to the workspace\n",
                "ml_client = MLClient(\n",
                "    credential=credential,\n",
                "    subscription_id=\"d8fadbca-7cc9-4ea1-b3e6-79a0507ca5b7\",\n",
                "    resource_group_name=\"az-ml-group\",\n",
                "    workspace_name=\"random_forest_ws\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Register local dataset\n",
                "\n",
                "This registers a Data object tha can be consumed as an input within a pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "name": "credit_data"
            },
            "outputs": [],
            "source": [
                "from azure.ai.ml.entities import Data\n",
                "from azure.ai.ml.constants import AssetTypes\n",
                "\n",
                "path = \"../data.csv\"\n",
                "\n",
                "data = Data(\n",
                "    name=\"data\",\n",
                "    path=path,\n",
                "    type=AssetTypes.URI_FILE,\n",
                "    description=\"Dataset for Interview\",\n",
                "    tags={\"source_type\": \"web\", \"source\": \"AzureML examples blob\"},\n",
                "    version=\"1.0.0\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "update-credit_data"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset with name data was registered to workspace, the dataset version is 1.0.0\n"
                    ]
                }
            ],
            "source": [
                "data = ml_client.data.create_or_update(data)\n",
                "print(f\"Dataset with name {data.name} was registered to workspace, the dataset version is {data.version}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create a conda environment for pipeline "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "name": "dependencies_dir"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# define conda.yml in ./dependencies\n",
                "dependencies_dir = \"./dependencies\"\n",
                "os.makedirs(dependencies_dir, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "conda.yaml"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Writing ./dependencies/conda.yaml\n"
                    ]
                }
            ],
            "source": [
                "%%writefile {dependencies_dir}/conda.yaml\n",
                "name: model-env\n",
                "channels:\n",
                "  - conda-forge\n",
                "dependencies:\n",
                "  - python=3.8\n",
                "  - numpy=1.21.2\n",
                "  - pip=21.2.4\n",
                "  - scikit-learn=0.24.2\n",
                "  - scipy=1.7.1\n",
                "  - pandas>=1.1,<1.2\n",
                "  - pip:\n",
                "    - inference-schema[numpy-support]==1.3.0\n",
                "    - xlrd==2.0.1\n",
                "    - azureml-mlflow==1.42.0"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create and register custom environment in the workspace:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "custom_env_name"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Environment with name random_forest_model is registered to workspace, the environment version is 0.1.1\n"
                    ]
                }
            ],
            "source": [
                "from azure.ai.ml.entities import Environment\n",
                "\n",
                "custom_env_name = \"random_forest_model\"\n",
                "\n",
                "pipeline_job_env = Environment(\n",
                "    name=custom_env_name,\n",
                "    description=\"Custom environment for random forest model pipeline\",\n",
                "    tags={\"scikit-learn\": \"0.24.2\"},\n",
                "    conda_file=os.path.join(dependencies_dir, \"conda.yaml\"),\n",
                "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
                "    version=\"0.1.1\",\n",
                ")\n",
                "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
                "\n",
                "print(\n",
                "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Build the pipeline\n",
                "\n",
                "This will consist of:\n",
                "1) data_transform component: Performs the task of splitting the data into train and test dataset\n",
                "2) data_train component: Trains a RandomForestRegression Model\n",
                "\n",
                "MLFlow will be used to log the parameters and metrics during our pipeline run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "data_prep_src_dir"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "data_transform_src_dir = \"./components/data_transform\"\n",
                "os.makedirs(data_transform_src_dir, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "def-main"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Overwriting ./components/data_transform/data_transform.py\n"
                    ]
                }
            ],
            "source": [
                "%%writefile {data_transform_src_dir}/data_transform.py\n",
                "\n",
                "import os\n",
                "import argparse\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "import logging\n",
                "import mlflow\n",
                "\n",
                "\n",
                "def main():\n",
                "    \"\"\"Main function of the script.\"\"\"\n",
                "\n",
                "    # input and output arguments\n",
                "    parser = argparse.ArgumentParser()\n",
                "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
                "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
                "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
                "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
                "    args = parser.parse_args()\n",
                "\n",
                "    # Start Logging\n",
                "    mlflow.start_run()\n",
                "\n",
                "    print(\"input data:\", args.data)\n",
                "    delimeter = \";\"\n",
                "    df = pd.read_csv(args.data, sep=delimeter)\n",
                "    df.columns = df.columns.str.lower()\n",
                "    df.columns = df.columns.str.replace(\" \", \"_\")\n",
                "    # drop feature with missing values\n",
                "    df.drop(\"feature_3\", axis=1, inplace=True)\n",
                "    # select best features + target\n",
                "    cols = [\"y\",\"feature_1\",\"feature_2\", \"feature_4\",\"feature_9\"]\n",
                "    df = df[cols]\n",
                "\n",
                "    mlflow.log_metric(\"num_samples\", df.shape[0])\n",
                "    mlflow.log_metric(\"num_features\", df.shape[1] - 1)\n",
                "\n",
                "    df_train, df_test = train_test_split(df,test_size=args.test_train_ratio,)\n",
                "\n",
                "    # output paths are mounted as folder, therefore, we are adding a filename to the path\n",
                "    df_train.to_csv(os.path.join(args.train_data, \"data.csv\"), index=False)\n",
                "\n",
                "    df_test.to_csv(os.path.join(args.test_data, \"data.csv\"), index=False)\n",
                "\n",
                "    # Stop Logging\n",
                "    mlflow.end_run()\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Create the Azure Ml component from data_transform.py script"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {
                "name": "data_prep_component"
            },
            "outputs": [],
            "source": [
                "from azure.ai.ml import command\n",
                "from azure.ai.ml import Input, Output\n",
                "\n",
                "data_transform_component = command(\n",
                "    name=\"data_transform_model_pipeline_fixed\",\n",
                "    display_name=\"Data transform for training\",\n",
                "    description=\"reads in data and transform\",\n",
                "    inputs={\n",
                "        \"data\": Input(type=\"uri_folder\"),\n",
                "        \"test_train_ratio\": Input(type=\"number\"),\n",
                "    },\n",
                "    outputs=dict(\n",
                "        train_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
                "        test_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
                "    ),\n",
                "    # The source folder of the component\n",
                "    code=data_transform_src_dir,\n",
                "    command=\"\"\"python data_transform.py \\\n",
                "            --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
                "            --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
                "            \"\"\",\n",
                "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "source": [
                "- Register the component to the workspace\n",
                "- Create (register) the component in the workspace"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Uploading data_transform (0.0 MBs): 100%|##########| 1599/1599 [00:00<00:00, 23514.93it/s]\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Component data_transform_model_pipeline_fixed with Version 2023-08-16-11-01-18-2189331 is registered\n"
                    ]
                }
            ],
            "source": [
                "# register the component to the workspace\n",
                "data_transform_component = ml_client.create_or_update(data_transform_component.component)\n",
                "\n",
                "# Create (register) the component in the workspace\n",
                "print(\n",
                "    f\"Component {data_transform_component.name} with Version {data_transform_component.version} is registered\"\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create training component \n",
                "\n",
                "- Consume the training and test data, train a tree based model and return the output model. You'll use Azure ML logging capabilities to record and visualize the learning progress.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "train_src_dir"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "train_src_dir = \"./components/train\"\n",
                "os.makedirs(train_src_dir, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "train.py"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Overwriting ./components/train/train.py\n"
                    ]
                }
            ],
            "source": [
                "%%writefile {train_src_dir}/train.py\n",
                "import argparse\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "import os\n",
                "import pandas as pd\n",
                "import mlflow\n",
                "\n",
                "\n",
                "def select_first_file(path):\n",
                "    \"\"\"Selects first file in folder, use under assumption there is only one file in folder\n",
                "    Args:\n",
                "        path (str): path to directory or file to choose\n",
                "    Returns:\n",
                "        str: full path of selected file\n",
                "    \"\"\"\n",
                "    files = os.listdir(path)\n",
                "    return os.path.join(path, files[0])\n",
                "\n",
                "\n",
                "# Start Logging\n",
                "mlflow.start_run()\n",
                "\n",
                "# enable autologging\n",
                "mlflow.sklearn.autolog()\n",
                "\n",
                "os.makedirs(\"./outputs\", exist_ok=True)\n",
                "\n",
                "\n",
                "def main():\n",
                "    \"\"\"Main function of the script.\"\"\"\n",
                "\n",
                "    # input and output arguments\n",
                "    parser = argparse.ArgumentParser()\n",
                "    parser.add_argument(\"--train_data\", type=str, help=\"path to train data\")\n",
                "    parser.add_argument(\"--test_data\", type=str, help=\"path to test data\")\n",
                "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
                "    parser.add_argument(\"--max_leaf_nodes\", required=False, default=50, type=int)\n",
                "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
                "    parser.add_argument(\"--model\", type=str, help=\"path to model file\")\n",
                "    args = parser.parse_args()\n",
                "\n",
                "    # paths are mounted as folder, therefore, we are selecting the file from folder\n",
                "    train_df = pd.read_csv(select_first_file(args.train_data))\n",
                "\n",
                "    # Extracting the label column\n",
                "    y_train = train_df.pop(\"y\")\n",
                "\n",
                "    # convert the dframe values to array\n",
                "    X_train = train_df.values\n",
                "\n",
                "    # paths are mounted as folder, therefore, we are selecting the file from folder\n",
                "    test_df = pd.read_csv(select_first_file(args.test_data))\n",
                "\n",
                "    # Extracting the label column\n",
                "    y_test = test_df.pop(\"y\")\n",
                "\n",
                "    # convert the dframe values to array\n",
                "    X_test = test_df.values\n",
                "\n",
                "    print(f\"Training with data of shape {X_train.shape}\")\n",
                "\n",
                "    model = RandomForestRegressor(\n",
                "        n_estimators=args.n_estimators, max_leaf_nodes=int(args.max_leaf_nodes)\n",
                "    )\n",
                "    model.fit(X_train, y_train)\n",
                "\n",
                "    y_pred = model.predict(X_test)\n",
                "\n",
                "    print(mean_absolute_error(y_test, y_pred))\n",
                "\n",
                "    # Registering the model to the workspace\n",
                "    print(\"Registering the model via MLFlow\")\n",
                "    mlflow.sklearn.log_model(\n",
                "        sk_model=model,\n",
                "        registered_model_name=args.registered_model_name,\n",
                "        artifact_path=args.registered_model_name,\n",
                "    )\n",
                "\n",
                "    # Saving the model to a file\n",
                "    mlflow.sklearn.save_model(\n",
                "        sk_model=model,\n",
                "        path=os.path.join(args.model, \"trained_model_3\"),\n",
                "    )\n",
                "\n",
                "    # Stop Logging\n",
                "    mlflow.end_run()\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- When the model is trained, the model file is saved and registered to the workspace. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "train.yml"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Overwriting ./components/train/train.yml\n"
                    ]
                }
            ],
            "source": [
                "%%writefile {train_src_dir}/train.yml\n",
                "# <component>\n",
                "name: train_random_forest_model_3\n",
                "display_name: Random Forest Train\n",
                "# version: 1 # Not specifying a version will automatically update the version\n",
                "type: command\n",
                "inputs:\n",
                "  train_data: \n",
                "    type: uri_folder\n",
                "  test_data: \n",
                "    type: uri_folder\n",
                "  max_leaf_nodes:\n",
                "    type: number     \n",
                "  registered_model_name:\n",
                "    type: string\n",
                "outputs:\n",
                "  model:\n",
                "    type: uri_folder\n",
                "code: .\n",
                "environment:\n",
                "  # for this step, we'll use an AzureML curate environment\n",
                "  azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\n",
                "command: >-\n",
                "  python train.py \n",
                "  --train_data ${{inputs.train_data}} \n",
                "  --test_data ${{inputs.test_data}} \n",
                "  --max_leaf_nodes ${{inputs.max_leaf_nodes}}\n",
                "  --registered_model_name ${{inputs.registered_model_name}} \n",
                "  --model ${{outputs.model}}\n",
                "# </component>\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create the component using `load_component()`. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "train_component"
            },
            "outputs": [],
            "source": [
                "# importing the Component Package\n",
                "from azure.ai.ml import load_component\n",
                "\n",
                "# Loading the component from the yml file\n",
                "train_component = load_component(source=os.path.join(train_src_dir, \"train.yml\"))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create and register the component:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "update-train_component"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Uploading train (0.0 MBs): 100%|##########| 3469/3469 [00:00<00:00, 12096.84it/s]\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Component train_random_forest_model_3 with Version 2023-08-16-11-09-51-1559769 is registered\n"
                    ]
                }
            ],
            "source": [
                "# Now we register the component to the workspace\n",
                "train_component = ml_client.create_or_update(train_component)\n",
                "\n",
                "# Create (register) the component in your workspace\n",
                "print(f\"Component {train_component.name} with Version {train_component.version} is registered\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build the pipeline from components\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Using *input data*, *split ratio* and *registered model name* as input variables. \n",
                "- Call the components and connect them via their inputs /outputs identifiers. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "pipeline"
            },
            "outputs": [],
            "source": [
                "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
                "from azure.ai.ml import dsl, Input, Output\n",
                "\n",
                "\n",
                "@dsl.pipeline(\n",
                "    compute=\"serverless\",\n",
                "    description=\"test_data_transform_train_pipeline_3\",\n",
                ")\n",
                "def model_pipeline_pipeline(\n",
                "    pipeline_job_data_input,\n",
                "    pipeline_job_test_train_ratio,\n",
                "    pipeline_job_max_leaf_nodes,\n",
                "    pipeline_job_registered_model_name,\n",
                "):\n",
                "    # using data_transform_function like a python call with its own inputs\n",
                "    data_transform_job = data_transform_component(\n",
                "        data=pipeline_job_data_input,\n",
                "        test_train_ratio=pipeline_job_test_train_ratio,\n",
                "    )\n",
                "\n",
                "    # using train_func like a python call with its own inputs\n",
                "    train_job = train_component(\n",
                "        train_data=data_transform_job.outputs.train_data,  # note: using outputs from previous step\n",
                "        test_data=data_transform_job.outputs.test_data,  # note: using outputs from previous step\n",
                "        max_leaf_nodes=pipeline_job_max_leaf_nodes,  # note: using a pipeline input as parameter\n",
                "        registered_model_name=pipeline_job_registered_model_name,\n",
                "    )\n",
                "\n",
                "    # a pipeline returns a dictionary of outputs\n",
                "    # keys will code for the pipeline output identifier\n",
                "    return {\n",
                "        \"pipeline_job_train_data\": data_transform_job.outputs.train_data,\n",
                "        \"pipeline_job_test_data\": data_transform_job.outputs.test_data,\n",
                "    }"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Submit the job\n",
                "\n",
                "- Use the pipeline definition to instantiate a pipeline with the: \n",
                "- dataset, split rate, max leaf nodes and the name of the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "registered_model_name"
            },
            "outputs": [],
            "source": [
                "registered_model_name = \"random_forest_pipeline_3\"\n",
                "\n",
                "# Let's instantiate the pipeline with the parameters of our choice\n",
                "pipeline = model_pipeline_pipeline(\n",
                "    pipeline_job_data_input=Input(type=\"uri_file\", path=data.path),\n",
                "    pipeline_job_test_train_ratio=0.25,\n",
                "    pipeline_job_max_leaf_nodes=50,\n",
                "    pipeline_job_registered_model_name=registered_model_name,\n",
                ")\n",
                "\n",
                "\n",
                "pipeline_job = ml_client.jobs.create_or_update(pipeline,experiment_name=\"random_forest_components_2\",)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Deploy the model as an online endpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "online_endpoint_name"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "credit-endpoint-e02c62eb\n"
                    ]
                }
            ],
            "source": [
                "import uuid\n",
                "import datetime\n",
                "\n",
                "#online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
                "# Creating a unique name for the endpoint\n",
                "\n",
                "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]\n",
                "print(online_endpoint_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "endpoint"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Endpint credit-endpoint-e02c62eb provisioning state: Succeeded\n"
                    ]
                }
            ],
            "source": [
                "from azure.ai.ml.entities import (\n",
                "    ManagedOnlineEndpoint,\n",
                "    ManagedOnlineDeployment,\n",
                "    Model,\n",
                "    Environment,\n",
                ")\n",
                "\n",
                "# create an online endpoint\n",
                "endpoint = ManagedOnlineEndpoint(\n",
                "    name=online_endpoint_name,\n",
                "    description=\"this is an online endpoint\",\n",
                "    auth_mode=\"key\",\n",
                "    tags={\n",
                "        \"training_dataset\": \"model_pipeline\",\n",
                "        \"model_type\": \"sklearn.RandomForestRegressor\",\n",
                "    },\n",
                ")\n",
                "\n",
                "endpoint_result = ml_client.begin_create_or_update(endpoint).result()\n",
                "\n",
                "print(f\"Endpint {endpoint_result.name} provisioning state: {endpoint_result.provisioning_state}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Check the registered endpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "update-endpoint"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Endpint \"credit-endpoint-e02c62eb\" with provisioning state \"Succeeded\" is retrieved\n"
                    ]
                }
            ],
            "source": [
                "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
                "\n",
                "print(f'Endpint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Deploy the model to the endpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "latest_model_version"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1"
                        ]
                    },
                    "execution_count": 122,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Let's pick the latest version of the model\n",
                "latest_model_version = max([int(m.version) for m in ml_client.models.list(name=registered_model_name)])\n",
                "\n",
                "print(latest_model_version)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {
                "name": "model"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Check: endpoint credit-endpoint-e02c62eb exists\n"
                    ]
                },
                {
                    "ename": "HttpResponseError",
                    "evalue": "(BadRequest) The request is invalid.\nCode: BadRequest\nMessage: The request is invalid.\nException Details:\t(InferencingClientCreateDeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_F4s_v2 in SubscriptionId d8fadbca-7cc9-4ea1-b3e6-79a0507ca5b7. Current usage/limit: 0/6. Additional needed: 8 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-0bf2c08c1aeea2f9a8fd4589aa239b0f-1ab549d5122254eb-01\"}\n\tCode: InferencingClientCreateDeploymentFailed\n\tMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_F4s_v2 in SubscriptionId d8fadbca-7cc9-4ea1-b3e6-79a0507ca5b7. Current usage/limit: 0/6. Additional needed: 8 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-0bf2c08c1aeea2f9a8fd4589aa239b0f-1ab549d5122254eb-01\"}\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"0bf2c08c1aeea2f9a8fd4589aa239b0f\",\n        \"request\": \"51d086f5367637de\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"northeurope\"\n}Type: Location\nInfo: {\n    \"value\": \"northeurope\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-08-16T12:09:27.3193443+00:00\"\n}",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[114], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# create an online deployment.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m blue_deployment \u001b[39m=\u001b[39m ManagedOnlineDeployment(\n\u001b[0;32m      7\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     endpoint_name\u001b[39m=\u001b[39monline_endpoint_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     instance_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m blue_deployment_results \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49monline_deployments\u001b[39m.\u001b[39;49mbegin_create_or_update(\n\u001b[0;32m     15\u001b[0m     blue_deployment\n\u001b[0;32m     16\u001b[0m )\u001b[39m.\u001b[39mresult()\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m     19\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDeployment \u001b[39m\u001b[39m{\u001b[39;00mblue_deployment_results\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m provisioning state: \u001b[39m\u001b[39m{\u001b[39;00mblue_deployment_results\u001b[39m.\u001b[39mprovisioning_state\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:263\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\operations\\_online_deployment_operations.py:215\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[1;34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     log_and_raise_error(ex)\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\operations\\_online_deployment_operations.py:210\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[1;34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[39mreturn\u001b[39;00m poller\n\u001b[0;32m    209\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 210\u001b[0m         \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    211\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\operations\\_online_deployment_operations.py:193\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[1;34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m         module_logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStarting deployment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m     deployment_rest \u001b[39m=\u001b[39m deployment\u001b[39m.\u001b[39m_to_rest_object(location\u001b[39m=\u001b[39mlocation)\n\u001b[1;32m--> 193\u001b[0m     poller \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_online_deployment\u001b[39m.\u001b[39mbegin_create_or_update(\n\u001b[0;32m    194\u001b[0m         resource_group_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_group_name,\n\u001b[0;32m    195\u001b[0m         workspace_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workspace_name,\n\u001b[0;32m    196\u001b[0m         endpoint_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mendpoint_name,\n\u001b[0;32m    197\u001b[0m         deployment_name\u001b[39m=\u001b[39mdeployment\u001b[39m.\u001b[39mname,\n\u001b[0;32m    198\u001b[0m         body\u001b[39m=\u001b[39mdeployment_rest,\n\u001b[0;32m    199\u001b[0m         polling\u001b[39m=\u001b[39mAzureMLPolling(\n\u001b[0;32m    200\u001b[0m             LROConfigurations\u001b[39m.\u001b[39mPOLL_INTERVAL,\n\u001b[0;32m    201\u001b[0m             path_format_arguments\u001b[39m=\u001b[39mpath_format_arguments,\n\u001b[0;32m    202\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_kwargs,\n\u001b[0;32m    203\u001b[0m         ),\n\u001b[0;32m    204\u001b[0m         polling_interval\u001b[39m=\u001b[39mLROConfigurations\u001b[39m.\u001b[39mPOLL_INTERVAL,\n\u001b[0;32m    205\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_kwargs,\n\u001b[0;32m    206\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m response, deserialized, headers: OnlineDeployment\u001b[39m.\u001b[39m_from_rest_object(deserialized),\n\u001b[0;32m    207\u001b[0m     )\n\u001b[0;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m poller\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\_restclient\\v2023_04_01_preview\\operations\\_online_deployments_operations.py:933\u001b[0m, in \u001b[0;36mOnlineDeploymentsOperations.begin_create_or_update\u001b[1;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, body, **kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m cont_token \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mcontinuation_token\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)  \u001b[39m# type: Optional[str]\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[39mif\u001b[39;00m cont_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 933\u001b[0m     raw_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_or_update_initial(\n\u001b[0;32m    934\u001b[0m         resource_group_name\u001b[39m=\u001b[39mresource_group_name,\n\u001b[0;32m    935\u001b[0m         workspace_name\u001b[39m=\u001b[39mworkspace_name,\n\u001b[0;32m    936\u001b[0m         endpoint_name\u001b[39m=\u001b[39mendpoint_name,\n\u001b[0;32m    937\u001b[0m         deployment_name\u001b[39m=\u001b[39mdeployment_name,\n\u001b[0;32m    938\u001b[0m         body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    939\u001b[0m         api_version\u001b[39m=\u001b[39mapi_version,\n\u001b[0;32m    940\u001b[0m         content_type\u001b[39m=\u001b[39mcontent_type,\n\u001b[0;32m    941\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x,y,z: x,\n\u001b[0;32m    942\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39merror_map\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    946\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_long_running_output\u001b[39m(pipeline_response):\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\_restclient\\v2023_04_01_preview\\operations\\_online_deployments_operations.py:864\u001b[0m, in \u001b[0;36mOnlineDeploymentsOperations._create_or_update_initial\u001b[1;34m(self, resource_group_name, workspace_name, endpoint_name, deployment_name, body, **kwargs)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m, \u001b[39m201\u001b[39m]:\n\u001b[0;32m    863\u001b[0m     map_error(status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code, response\u001b[39m=\u001b[39mresponse, error_map\u001b[39m=\u001b[39merror_map)\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, error_format\u001b[39m=\u001b[39mARMErrorFormat)\n\u001b[0;32m    866\u001b[0m response_headers \u001b[39m=\u001b[39m {}\n\u001b[0;32m    867\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n",
                        "\u001b[1;31mHttpResponseError\u001b[0m: (BadRequest) The request is invalid.\nCode: BadRequest\nMessage: The request is invalid.\nException Details:\t(InferencingClientCreateDeploymentFailed) InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_F4s_v2 in SubscriptionId d8fadbca-7cc9-4ea1-b3e6-79a0507ca5b7. Current usage/limit: 0/6. Additional needed: 8 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-0bf2c08c1aeea2f9a8fd4589aa239b0f-1ab549d5122254eb-01\"}\n\tCode: InferencingClientCreateDeploymentFailed\n\tMessage: InferencingClient HttpRequest error, error detail: {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_F4s_v2 in SubscriptionId d8fadbca-7cc9-4ea1-b3e6-79a0507ca5b7. Current usage/limit: 0/6. Additional needed: 8 Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-outofquota\"]},\"type\":\"https://tools.ietf.org/html/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-0bf2c08c1aeea2f9a8fd4589aa239b0f-1ab549d5122254eb-01\"}\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"0bf2c08c1aeea2f9a8fd4589aa239b0f\",\n        \"request\": \"51d086f5367637de\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"northeurope\"\n}Type: Location\nInfo: {\n    \"value\": \"northeurope\"\n}Type: Time\nInfo: {\n    \"value\": \"2023-08-16T12:09:27.3193443+00:00\"\n}"
                    ]
                }
            ],
            "source": [
                "# picking the model to deploy. Here we use the latest version of our registered model\n",
                "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
                "\n",
                "\n",
                "# create an online deployment.\n",
                "blue_deployment = ManagedOnlineDeployment(\n",
                "    name=\"blue\",\n",
                "    endpoint_name=online_endpoint_name,\n",
                "    model=model,\n",
                "    instance_type=\"Standard_F4s_v2\",\n",
                "    instance_count=1,\n",
                ")\n",
                "\n",
                "blue_deployment_results = ml_client.online_deployments.begin_create_or_update(\n",
                "    blue_deployment\n",
                ").result()\n",
                "\n",
                "print(\n",
                "    f\"Deployment {blue_deployment_results.name} provisioning state: {blue_deployment_results.provisioning_state}\"\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Test with a sample query\n",
                "\n",
                "Now that the model is deployed to the endpoint, you can run inference with it.\n",
                "\n",
                "Create a sample request file following the design expected in the run method in the score script."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "metadata": {
                "name": "sample-request.json"
            },
            "outputs": [],
            "source": [
                "deploy_dir = \"./deploy\"\n",
                "os.makedirs(deploy_dir, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "metadata": {
                "name": "write-sample-request"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Writing ./deploy/sample-request.json\n"
                    ]
                }
            ],
            "source": [
                "%%writefile {deploy_dir}/sample-request.json\n",
                "{\n",
                "    \"input_data\": {\n",
                "    \"columns\": [\"feature_1\",\"feature_2\", \"feature_4\",\"feature_9\"],\n",
                "    \"index\": [0, 1, 2, 3],\n",
                "    \"data\": [\n",
                "            [16, 34472, 90, 1260],\n",
                "            [20, 33329, 97, 1100],\n",
                "            [20, 31850, 110, 1120],\n",
                "            [17, 30351, 90, 1260]\n",
                "\n",
                "    ]\n",
                "  }\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {
                "attributes": {
                    "classes": [
                        "Python"
                    ],
                    "id": ""
                },
                "name": "ml_client.online_endpoints.invoke"
            },
            "outputs": [
                {
                    "ename": "ValidationException",
                    "evalue": "Deployment name blue not found for this endpoint",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mValidationException\u001b[0m                       Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test the blue deployment with some sample data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ml_client\u001b[39m.\u001b[39;49monline_endpoints\u001b[39m.\u001b[39;49minvoke(\n\u001b[0;32m      3\u001b[0m     endpoint_name\u001b[39m=\u001b[39;49monline_endpoint_name,\n\u001b[0;32m      4\u001b[0m     request_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./deploy/sample-request.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     deployment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:263\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\operations\\_online_endpoint_operations.py:329\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.invoke\u001b[1;34m(self, endpoint_name, request_file, deployment_name, input_data, params_override, local, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39m# Until this bug is resolved https://msdata.visualstudio.com/Vienna/_workitems/edit/1446538\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m deployment_name:\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_deployment_name(endpoint_name, deployment_name)\n\u001b[0;32m    331\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(request_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    332\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(f\u001b[39m.\u001b[39mread())\n",
                        "File \u001b[1;32mc:\\Users\\mustafaj\\AppData\\Local\\miniconda3\\envs\\azure_ml_cli\\lib\\site-packages\\azure\\ai\\ml\\operations\\_online_endpoint_operations.py:439\u001b[0m, in \u001b[0;36mOnlineEndpointOperations._validate_deployment_name\u001b[1;34m(self, endpoint_name, deployment_name)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m deployments_list:\n\u001b[0;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m deployment_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m deployments_list:\n\u001b[1;32m--> 439\u001b[0m         \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[0;32m    440\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDeployment name \u001b[39m\u001b[39m{\u001b[39;00mdeployment_name\u001b[39m}\u001b[39;00m\u001b[39m not found for this endpoint\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    441\u001b[0m             target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mONLINE_ENDPOINT,\n\u001b[0;32m    442\u001b[0m             no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDeployment name not found for this endpoint\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    443\u001b[0m             error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[0;32m    444\u001b[0m             error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mRESOURCE_NOT_FOUND,\n\u001b[0;32m    445\u001b[0m         )\n\u001b[0;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNo deployment exists for this endpoint\u001b[39m\u001b[39m\"\u001b[39m\n",
                        "\u001b[1;31mValidationException\u001b[0m: Deployment name blue not found for this endpoint"
                    ]
                }
            ],
            "source": [
                "# test the blue deployment with some sample data\n",
                "ml_client.online_endpoints.invoke(\n",
                "    endpoint_name=online_endpoint_name,\n",
                "    request_file=\"./deploy/sample-request.json\",\n",
                "    deployment_name=\"blue\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Clean up endpoint\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "attributes": {
                    "classes": [
                        "python "
                    ],
                    "id": ""
                },
                "name": "ml_client.online_endpoints.begin_delete"
            },
            "outputs": [],
            "source": [
                "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#run_id = \"keen_rain_syxc8yg2tj\"\n",
                "!az ml model create --name model-pipeline-mixed --version 1 --path \"azureml://locations/northeurope/workspaces/45824f33-6edb-4ec0-a385-a59e6afa8e5b/models/random_forest_pipeline_3/versions/1\" --type mlflow_model\n"
            ]
        }
    ],
    "metadata": {
        "celltoolbar": "Edit Metadata",
        "description": {
            "description": "Create production ML pipelines with Python SDK v2 in a Jupyter notebook"
        },
        "kernelspec": {
            "display_name": "azure_ml_cli",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "nteract": {
            "version": "nteract-front-end@1.0.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
